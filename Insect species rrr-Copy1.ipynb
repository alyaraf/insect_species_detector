{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c696ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9b23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = r\"C:\\\\Users\\\\alyar\\\\Downloads\\\\hackathon-2-insect-species-classification\"\n",
    "train_dir = os.path.join(data_dir, \"train\", \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\", \"test\")\n",
    "csv_path = os.path.join(data_dir, \"train.csv\")\n",
    "\n",
    "# Load CSV file\n",
    "data = pd.read_csv(csv_path)\n",
    "data[\"ID\"] = data[\"ID\"].apply(lambda x: os.path.join(train_dir, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c8ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, stratify=data[\"Species\"], random_state=42)\n",
    "\n",
    "# ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8cd203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6872 validated image filenames belonging to 37 classes.\n",
      "Found 1719 validated image filenames belonging to 37 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow from dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Species\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Species\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbe6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 with pre-trained weights\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(len(train_generator.class_indices), activation=\"softmax\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84582d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: []\n",
      "Epoch 1/5\n",
      "214/214 [==============================] - 284s 1s/step - loss: 0.0799 - accuracy: 0.9789 - val_loss: 0.7911 - val_accuracy: 0.8992\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 288s 1s/step - loss: 0.0730 - accuracy: 0.9800 - val_loss: 0.7468 - val_accuracy: 0.8933\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 290s 1s/step - loss: 0.0552 - accuracy: 0.9851 - val_loss: 0.7440 - val_accuracy: 0.8921\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 292s 1s/step - loss: 0.0583 - accuracy: 0.9838 - val_loss: 0.7060 - val_accuracy: 0.8945\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 302s 1s/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.6895 - val_accuracy: 0.8939\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 321s 1s/step - loss: 0.0647 - accuracy: 0.9827 - val_loss: 0.6732 - val_accuracy: 0.8933\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 310s 1s/step - loss: 0.0627 - accuracy: 0.9819 - val_loss: 0.6756 - val_accuracy: 0.8962\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 309s 1s/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.6704 - val_accuracy: 0.8921\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 302s 1s/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 0.6780 - val_accuracy: 0.8933\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 308s 1s/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.6552 - val_accuracy: 0.8939\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 307s 1s/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 0.6649 - val_accuracy: 0.8927\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 299s 1s/step - loss: 0.0525 - accuracy: 0.9855 - val_loss: 0.6595 - val_accuracy: 0.8974\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 310s 1s/step - loss: 0.0621 - accuracy: 0.9838 - val_loss: 0.6604 - val_accuracy: 0.8909\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 312s 1s/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.6601 - val_accuracy: 0.8903\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 305s 1s/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.6385 - val_accuracy: 0.8927\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 298s 1s/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.6415 - val_accuracy: 0.8962\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 295s 1s/step - loss: 0.0436 - accuracy: 0.9863 - val_loss: 0.6405 - val_accuracy: 0.8939\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 296s 1s/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.6598 - val_accuracy: 0.8956\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 299s 1s/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.6725 - val_accuracy: 0.8962\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 302s 1s/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.6536 - val_accuracy: 0.8945\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 299s 1s/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.6601 - val_accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Ensure the model uses the GPU\n",
    "print(\"Running on GPU: \" + str(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "# Unfreeze the base model and fine-tune\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = 10 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6d797e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2149 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('jpg', 'png', 'jpeg'))]\n",
    "test_df = pd.DataFrame({\"ID\": test_files})\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,  # Add rotation during inference\n",
    "    zoom_range=0.2,     # Add zoom during inference\n",
    "    horizontal_flip=True,\n",
    "    x_col=\"ID\",\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "276cc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Test-Time Augmentation (TTA)\n",
    "def perform_tta(generator, model, num_augments=10):\n",
    "    augmented_predictions = []\n",
    "    for _ in range(num_augments):\n",
    "        # Reset the generator to ensure new augmentations are applied\n",
    "        generator.reset()\n",
    "        # Introduce more variety to TTA\n",
    "        generator.image_data_generator.rotation_range = 30  # Increase rotation range\n",
    "        generator.image_data_generator.zoom_range = [0.8, 1.2]  # Dynamic zoom range\n",
    "        generator.image_data_generator.brightness_range = [0.8, 1.2]  # Add brightness variations\n",
    "        generator.image_data_generator.horizontal_flip = True  # Flip images horizontally\n",
    "        generator.image_data_generator.shear_range = 20  # Add shear transformations\n",
    "        augmented_predictions.append(model.predict(generator, verbose=0))\n",
    "    return tf.reduce_mean(augmented_predictions, axis=0)\n",
    "\n",
    "# Make predictions with TTA\n",
    "predictions = perform_tta(test_generator, model, num_augments=5)\n",
    "predicted_classes = tf.argmax(predictions, axis=1).numpy()\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
    "predicted_species = [class_indices[idx] for idx in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb923e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictionss.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for predictions\n",
    "filenames = test_generator.filenames\n",
    "filenames = [os.path.basename(f) for f in filenames]  # Extract only the image names\n",
    "results = pd.DataFrame({\"ID\": filenames, \"Species\": predicted_species})\n",
    "\n",
    "# Save predictions to CSV\n",
    "results.to_csv(os.path.join(data_dir, \"predictionss.csv\"), index=False)\n",
    "print(\"Predictions saved to predictionss.csv\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"insect_species_classifier_resnet.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94758183",
   "metadata": {},
   "source": [
    "train 50 epochs in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d5f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
